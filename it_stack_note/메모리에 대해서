1.2 메모리에 대해서
  메모리는 저장이라는 뜻이다. 컴퓨터에는 두가지 저장 개념이 있다. 오래 저장하는 것과 잠깐 저장하는 것 오래 저장하는 것은 파일이라는 형태로 디스크에 저장이 되며 디스크는 우리가 이해하는 하드디스크이다.
  저장하는 것은 명령어나 데이터의 형태로 메모리에 저장되는 것이며 프로그램을 종료했을 때 또는 컴퓨터를 껐을 때 심지어 프로그램을 종료하지 않았는데도 사라지는 경우가 있다.
  이렇게 단기적인 기억을 위해서 메모리가 존재하는 이유는 컴퓨터의 전체적인 성능을 높이기 위한 것이다.
  컴퓨터의 성능은 무엇에 좌우될까?
  처음 설명한 CPU 연산의 능력, 속도이다. 속도는 클럭으로 표현을 하였다. 빠르게 처리하는 것이 컴퓨터의 성능이다.
  메모리가 왜 컴퓨터의 전체 성능을 좌우할까?
  CPU가 일을 하려면 일의 내용이 CPU로 전달이 되어야 한다. 이 명령어나 데이터는 파일에 일부로 담겨있다. 파일은 하드디스크에 저장이 되어 있다.
  파일의 일부 내용이 하드디스크에서 CPU까지 전달하려면 데이터가 BUS를 타야한다. 컴퓨터 안에도 버스가 있다. BUS의 약어를 찾아봐도 나오지 않는거로 봐서는 우리가 타는 BUS에서 유래되었다고 생각해도 될 것 같다.
  개념적으로는 같다. 컴퓨터 안에 데이터들을 싣어 날라주는 연결선이다. 데이터 버스 이렇게 부른다.
  그러면 하드디스크에 있는 파일의 일부가 이 버스를 타고 CPU로 올라간다. CPU에서 일처리가 끝나면 결과가 다시 버스를 타고 어디론가 흘러간다. 이렇게 버스로 컴퓨터 안에서 오간다.
  이때 문제는 버스가 상대적으로 느리다는 것이다. 상대적이라는 말을 이해해야 하는 것은 컴퓨터 안에서 데이터가 오가는 속도는 굉장히 빠르다.
  사실 하드디스크가 느리다고 말하지만, 엄청난 속도로 실린더를 돌고있다. CPU가 빠른 처리를 하기 위해 하드디스크의 파일의 내용 일부를 메모리에 올려 놓고 수행을 한다.
  여기서 자꾸 프로그램의 일부라고 하는 이유는 프로그램이 얼마나 큰가 그 파일이 메모리에 한꺼번에 올라가는 것이 아니다.
  메모리는 매우 한정된 공간이기 때문에 프로그램 중 일부가 올라가는 것이다. 메모리는 CPU가 하고자 하는 일을 임시 저장한다. 
  메모리는 하드디스크보다 훨씬 속도가 빠르기 때문에 CPU의 일거라를 바로바로 줄 수가 있다. 그래서 CPU가 얼마나 빨리 처리하느냐도 중요하지만, 옆에 일을 얼마나 많이 잘 대기 시켜줄 수 있느냐도 중요하다.
  메모리는 그래서 일을 쌓아두는 임시 창고 같은 곳이다. 그래서 그 창고의 크기가 중요하다. 그래서 CPU는 속도가 중요하고 메모리는 크키가 중요하다.
  사실 메모리를 많이 쓰게 되면 속도는 빨라질 수 있다. 하지만 창고가 크다고 해서 일처리가 느리다면 메모리만 많다고 일이 빨리지는 것은 아닐 것이다. 전체 컴퓨터 성능에는 영향을 미친다.
  메모리가 많아야 하는 경우는 어떤 경우 일까?
  일처리를 빨리만 해야 한다면 사실 CPU의 성능이 중요할텐데, 메모리가 많아지면 성능이 좋아질 수 있는 경우는 많은 양의 데이터를 한꺼번에 메모리에 올려 실행하는 프로그램이 있는 경우이다.
  대표적인 것이 게임이다. 최근 게임들을 보면 용량이 엄청 크다. 그래픽 사양도 높다. 한꺼번에 메모리에 올려야할 파일도 많아진다.
  그리고 여러개의 작업을 동시에 많이 하는 경우라면 메모리가 많이 필요하다. 이유는 메모리에 여러개의 프로그램의 일부분이 올라가기 때문이다.

1.2.1 메모리 동작 원리
  기억 소자로 구성된 메모리 일반적으로 메모리라고 하면 기억이라는 개념이다. 컴퓨터에서 말하는 메모리는 기억소자 즉 반도체를 의미한다.
  반도체는 특성상 전류를 흐르게도 하고 흐르지 않게도 하는 특징이 있다. 이를 이용해서 임시적인 내용들을 기억하게 만드는 것이다.
  컴퓨터는 이진 1과0으로 값을 저장하기 때문에 기억 소자는 상태가 ON 인지 OFF인지 수준으로 기억하게 되는 것이다.
  반도체 기억장치의 기본 요소는 기억 소자(memory cell)이다. 모든 반도체 기억소자들이 갖는 공통적인 성질이 있다.
  두개의 안정된 상태를 갖는다. 1과 0이다. 상태를 세트할 수 있도록 쓰여질 수 있다. 상태를 감지할 수 있도록 얽혀질 수 있다.
  쓰는 동작인 경우는 기억 소자의 상태를 1또는 0으로 만들어 준다는 의미이고 읽기 동작이라는 것은 그 소자가 갖는 현재 상태가 어떠한 상태인지를 알아오는 개념이다.
  기억 장소라는 개념에서 확장하면 저장 장소라는 개념의 하드디스크, CD/DVD, USB저장장치와 같은 보조 기억장치까지를 의미한다.
  메모리가 이런 저장장치와의 차이는 휘발성이라는 특징이다. 시스템이 활성화 된 상태에서 그 값을 기억하고 있다가 다시 시스템의 shutdown과 함께 지워지게 된다.
  그리고 저장/읽기 속도 면에서 현저하게 차이가 난다. CPU와 가장 가까이 있는 레지스터 메모리, 캐시 메모리, 주기억 장치, 보조기억 장치는 각각 아래와 같이 그 특성이 차이가 있다.
  메모리 동작 메모리는 정보에 대해서 1또는 0으로 저장이 되는데, 이 정보를 유지하기 위해서는 전기적으로 연속으로 재충전이 되어야 한다.
  이를 리프래시라 하고 메모리 타이밍이라고 한다. 메모리는 정보를 저장(write)하거나 저장된 정보를 읽기(read) 위하여 바둑판과 같이 열(raw, 가로)과 행(column, 세로)으로 구성된
  martrix(행렬)구조의 주소(address)를 가지고 있다. 이를 두고 CAS(Column Address Strobe)와 RAS(Row Address Strobe)라 부르는데 프로세서가 메모리에 있는 정보를 읽거나 메모리에 정보를 기록할 때는
  먼저 가로줄에 신호(RAS)를 보내고 나서 세로줄에 신호(CAS)를 보내어 주소를 확인한다.
  어떤 주소에 데이터가 들어있는지 아니면 비어 있는지는 CAS가 담당하며 CAS 신호가 없어지면 그 주소에 다시 새로운 정보를 저장한다.
  메모리 동작 과정 메모리의 동작과정은 다음과 같다.
  1) CPU가 메인보드 칩셋에 데이터를 요청하면 메인보드 칩셋은 그 데이터가 있는 곳의 행(raw, 가로)주소를 메모리에 보낸다. 이것을 하는데는 각각 1사이클(Hz)가 걸린다.
  2) 행 주소가 메모리의 행 주소 버퍼로 들어오면, 센스 엠프(sense amp)가 그 행에 들어있는 모든 셀을 읽어낸다. 이렇게 행 부분을 읽는 신호는 RAS(row address strobe, 행 주소 스트로브)
      라고 부르고, 읽는데 걸리는 시간은 RAS-to-CAS delay(RAS와 CAS 사이의 지연시간)라고한다. 이 과정은 2~3사이클이 걸린다.
  3) 행 주소만으로는 필요한 데이터가 어디 있는지 알 수 없으니 이번에는 열(세로 줄) 주소를 받는다. 그러면 CAS(column address strube, 열 주소 스트로브)신호가 일어나 정확히 열을 찾아낸다.
      이때 걸리는 시간을 CAS latency(CAS 지연시간)라고 한다. 이것을 하는데도 역시 2~3 사이클이 걸린다.
  4) 정확한 행과 열을 찾았으니 필요한 데이터를 찾은 셈이다. 메모리 셀에 있는 내용이 출력 버퍼(output buffer)로 옮겨진다. 이 것을 하는데는 1사이클이 걸린다.
  5) 마지막으로 메인보드 칩셋이 출력 버퍼의 내용을 읽고 CPU로 전달한다. 이때 각각 1사이클씩 모두 2사이클이 걸린다.

  메모리 성능 메모리의 속도는 메모리가 CPU와 데이터를 주고 빋는 시간을 말한다. 이를 엑세스라 부르며 단위는 ns(nano-secode) - 10억분의 1초로써 메모리 속도의 기준이 된다.
  리프레시 시간 메모리는 일정 시간마다 재충전을 해줘야 하는데, 그렇지 않으면 정보는 사라지게 된다. 이 일정기간을 리프레시 시간이라고 한다. 이는 메모리에서 한 번 읽고 나서 다시 읽을 수 있는 사이 시간을 말한다.
  메모리 엑세스 시간 메모리 엑세스 시간은 데이터를 읽어오라는 명령을 받고 데이터를 읽기 시작하기까지의 시간을 말한다. CPU에서 명령어를 처리할 떄 명령어가 갖는 주소인 CAS, RAS 데이터를 보낸다.
  그러면 CPU에 그 주소에 해당하는 값을 가져오게 되는데 걸리는 시간이 엑세스 시간이다.
  사이클 시간 사이클 시간은 메모리 작업이 완료와 동시에 대기 신호를 내놓은 후 다음 신호를 받을 준비가 되었다는 신호를 주기까지의 시간이다.
  사이클 시간 = 메모리 엑세스 시간 + 리프레시 시간

1.2.2 메모리의 종류
  메모리의 분류 RAM(Random Access Memory)는 주기억 장치에서 사용되며 자료 저장 방식, 형태별, 사용처에 따라서 메모리를 분류할 수 있다.
  1) 자료 저장 방식에 따른 분류 = 자료 저장 방식에 따른 분류로 정적인 방식과 동적인 방식으로 나눌 수 있다. 이는 SRAM(Static RAM)과 DRAM(Dynamic RAM)으로 나뉘는데,
      DRAM은 캐패시터에 전하를 충전하는 방식으로 데이터를 저장하는 기억 소자들로 이루어진 것이고 저장 내용을 기억하기 위해서는 주기적인 재충전이 필요한 방식이다.
      정적인 방식은 플리플롭을 이용한 방식으로 고정된 값을 기억하는 방식으로 재충전이 필요하지 않은 방식이다.
  2) 형태에 따른 분류 = 램 모듈의 형태상에 따라서 램의 소켓과 접촉하는 면의 핀 수에 따라서 30핀, 72핀, 168핀, 184핀으로 나뉜다. 그리고 내부적인 선이나 형태에 따라서 구분된다.
      분류 DIP메모리를 소켓에 하나씩 설치하는 방식으로 예전의 286용 메인보드에 이전에 주로 사용하던 방식 SIMM(Single In Line Memory Module) PCB양면의 접점이 같은 신호선을 사용한다는
      의미로써 8 ~ 16 비트 데이터 대역폭을 가지며 주로 286 ~ 486 에서 30핀, 72핀으로 사용하던 방식 DIMM(Dual In Line Memory Module) PCB 양면의 접점이 다른 신호선을 사용한다는 의미인데,
      이것은 양면의 SIMM이라고 볼 수 있으며 양면 램이라고 한다.
      64 비트의 데이터 버스를 지원 데스크탑과 서버 시스템에서 채택하고 양면의 SIMM으로 메모리 모듈의 밀도를 증가시킨 것이다. 노트북에는 SO(Small-Out line)DIMM(144핀)을 사용하고
      현재는 168핀 DIMM이 현재 가장 보편적으로 쓰이고 있는 램의 형태이다. RIMM(Rambus In Line Memory Module) Rambus DRAM을 모듈화한 제품으로 DIMM보다 고속이며 앞으로 많이 사용될 제품이다.
      시스템을 종료 시키지 않고도 RAM을 교체할 수 있는 특징을 가지고 있다.
  3) 사용처에 따른 분류 = ROM BIOS(Programmable ROM) 70년대 후반에 Texas Instrument에서 개발되었으며 단 한 번만 기록할 수 있는 ROM이다.
      EPROM(Erasable Programmable ROM) 기록한 자료를 수정할 수 있는 ROM으로 자외선을 사용한다.
      EEPROM(Electrical Erasable Programmable ROM) 전기 신호를 사용하여 자료를 기록하고 수정할 수 있는 ROM이다. Flash Memory EEPROM을 변형한 것으로 전원 공급이 없어도
      기록된 내용을 보존하는 ROM의 특성과 기록된 내용을 자유롭게 수정할 수 있는 RAM의 특성을 가지고 있다.
      EEPROM보다는 속도가 느리고, PC카드(PCMCIA)로서 하드디스크 내용으로 사용되기도 한다. SSD(Solid State Disk)개념의 하드디스크로써의 형태로 제품화가 되고 있다.
      FPM(Fast Page Mode) DRAM 페이지(16KB)단위로 데이터를 입출력하며 작동주기는 3사이클, 486이전의 CPU에서 30핀 SIMM, 72핀 SIMM형태로 메인보드에 설치되었다.
      EDO(Exchange Data Output) DRAM 기본구조는 FPM DRAM과 비슷하며 작동주기는 2사이클, 효율적으로 대처할 수 있는 CPU의 최고 클럭 속도는 66MHz정도이며 보통 72핀 SIMM형태이다.
      BEDO(Burst Extended Data Output) DRAM 매 클럭 사이클마다 RAM 메모리 주소에서 프로세서로 정보를 전달하는 특별한 형태의 EDO RAM, 데이터를 큰 덩어리 형태로 전달하고
      이것을 잘게 나누어 연속적으로 폭발하듯이 처리하는 기술이다.

  DRAM의 종류
  1) 동기식 DRAM(Synchronous DRAM) - 가장 널리 사용되고 있는 DRAM의 형태는 동기식 DRAM이다.
      전통적인 DRAM과는 달리 외부 클록 신호와 동기화 되어 대기 상태 없이 프로세스/기억장치 버스의 전속력으로 실행되고 있는 프로세서와 데이터를 교환한다.
      전통적인 DRAM의 경우 프로세서는 주소와 제어 신호를 기억장치로 보내어서 읽히거나 쓰여질 데이터를 가리킨다. 엑세스 시간만큼 지연된 후 DRAM은 데이터를 쓰거나 읽는다.
      하지만 동기식 엑세스는 시스템 클록의 제어 하에 데이터를 받고 내보내게 된다.
  2) Rambus DRAM - 인텔이 펜티엄과 이타늄 프로세서를 위해 채택하였다. RDRAM은 비동기식 블록 지향 프로토콜(asynchronous block-oriented protocol)을 이용하여 주소와 제어 정보를 전달한다.
      기존에 사용되었던 RAS, CAS, R/W 신호에 의해서 제어되지 않고, 고속 버스(high-speed bus)를 통하여 기억장치 요구를 받는다.
      이를 통해서 기존 DRAM보다 상대적으로 향상된 속도가 된다.
  3) 인텔의 터보 메모리 - 최근에 노트북에서 많이 대입되는 테보메모리라는 이름으로 인텔에서 메모리를 만들었다.
      랜덤 액세스 성능이 하드디스크보다 우수한 NAND 플래쉬 메모리를 별도의 캐쉬 영역에 할당하여, 데스크탑과 비교해 느린 속도인 노트북 하드디스크의 퍼포먼스를 향상시키고,
      노트북의 사용 환경에 맞는 서비스를 제공하기 위한 목적으로 개발됐다. 윈도우 비스타의 핵심 기능인 Ready Boost와 Ready Drive와 연동되는 것으로 그 이하 OS에서는 사용할 수 없다.
      향후 SSD같은 형태의 디스크로의 도입과 더불어서 중간단계에서의 메모리 형태로 전환을 통해서 메모리를 통한 전체 시스템 성능을 높여가고 있다.

1.2.2 캐시 메모리(Cache Memory) 개념, 기법
  Cache Memory는 메인 메모리와 CPU간의 데이터 속도 향상을 위한 중간 버퍼 역할을 하는 CPU내 또는 외에 존재하는 메모리이다.
  전체 시스템의 성능의 개선을 시킬 수 있는 메모리이다.
  캐시는 종종 듣게 된다. 캐시 된 거 아니야? 라느 말을 하기도 하고, 캐시되어 있어서 빠른거야 라는 말을 하기도 한다. 캐시는 잠시 저장해둔다는 의미이고 기능이다.
  캐시 메모리라고 하면 실제 메모리와 CPU사이에서 빠르게 전달하기 위해서 미리 데이터들을 저장해두는 좀 더 빠른 메모리이다.
  네트워크에서 캐시는 로컬에 파일을 미리 받아놓고, 그 내용을 보거나 웹서버에서도 매번 로딩을 해야 하는 파일들을 미리 로딩해두고, 응답을 주기도 한다.
  데이터 베이스를 매번 확인해야 하는 것도 캐시서버를 이용한다면 빠른 응답을 줄 수 있다.
  캐시의 원리를 이용한 캐시 서버를 활용하여 CDN같은 서비스도 할 수 있다. CDN은 컨텐츠를 딜리버리 해주는 서버이다. 아주 먼 곳에 있는 파일을 매번 가져와야 한다면 네트워크 구간이 멀어서 실패율도 있고,
  전송 속도가 느리고, 오래 걸릴 수 있다. 이를 자주 쓰는 파일들을 가까운 지역의 서버에 올려 놓는다. 그렇게 되면 빠른 접근이 가능해진다.
  캐시라는 개념은 동일하며, 그것을 컴퓨터 내부에서 쓰느냐 웹서버와 클라이언트 사이에서 쓰느냐, 네터워크에서 파일을 전송시도 다양하게 사용이 가능하다.
  데이터를 고속으로 엑세스 할 수 있다는 장점이 있다. 치명적인 단점도 있다. 특성을 알고 사용하기 때문에 단점이라고 말할 수 없지만, 캐시서버 또는 캐시 메모리 등 캐시가 붙은 기능에
  저장된 데이터는 지워질 수 있다는 전제로 한다. 영구적 메모리 공간이 아니다. 언제든 지워질 수 있고, 그것을 당연시 생각하고 프로그램 또는 서버를 개발해야 한다.
  그리고 캐시는 되도록 빈도수가 높은 것들 위주로 데이터량이 많지 않은 것이 좋다. 캐시메모리 서브 등 캐시가 붙은 장치는 비싸다. 그래서 이곳에 모든 데이터를 넣고, 서비스를 할 생각은 말아야 한다.
  데이터의 임시 보관소 Cache Memory 'Cache'라는 의미는 보관이나 저장의 의미이다. Cache Memory라 하면 이러한 역할을 하는 물리적 장치 즉 메모리라 말한다.
  CPU와 메인 메모리 사이에 존재한다고 말할 수 있는데, CPU내에 존재할 수도 있고 역할이나 성능에 따라서는 CPU밖에 존재할 수도 있다.
  빠른 CPU의 처리속도와 상대적으로 느린 메인 메모리에서의 속도의 차이를 극복하는 중간 버퍼 역할을 한다. 쉽게 표현하면 CPU는 빠르게 일을 진행하고 있는데, 메모리에서 데이터를 가져오고 가져가는데
  느려서 중간에 미리 CPU에 전달될 데이터를 들고 서 있는 형태라고 말할 수 있다.
  Cache Memory의 성능
  Cache의 크기 Cache Memory의 크기가 크면 Hit율과 반비례 관계
  인출방식(Fetch Algorithm) 요구 인출(Demand Fetch) : 필요 시 요구하여 인출하는 방식
  선 인출(Pre-Fetch) : 예상되는 데이터를 미리 인출하는 방식
  쓰기 정책(Write Policy) Write-Through : 주기억 장치와 캐시에 동시에 쓰는 방식
  Write-Back : 데이터 변경만 캐시에 기록 교체(Replace) 알고리즘 Cache Miss 발생시 기존 메모리와 교체하는 방식 FIFO, LRU, LFU, Random, Optimal, Belady's MIN(향후 가장 참조 되지 않을 블록을 교체)
  사상(Mapping)기법 주기억 장치의 블록을 적재할 캐시 내의 위치를 지정하는 방법
  직접 사상, 완전 연관 사상, 집합 연관 사상, Cache Memory는 메인 메모리의 일정 블록 사이즈의 데이터를 담아 두었다가 CPU에게 워드 사이즈 만큼의 데이터를 전송하게 된다.
  이때 이 사이즈들이 캐시의 성능에 영향을 미치게 된다. 블롟사이즈나 워드 사이즈가 상대적으로 크다면 그만큼 Cache의 Hit률이 높아지기 때문이다.
  
